{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2 as p\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play by play file structure \n",
    "# PlayByPlay\\Play By Play\\Year\\Play By Play\\JSON\\Week\\flattened\\files \n",
    "\n",
    "# path to entire play by play folder\n",
    "folder = r'C:\\Users\\mmgri\\Desktop\\PlayByPlay'\n",
    "\n",
    "# creating database connection string\n",
    "conn = p.connect(\"host=capstonealaindexing2018.postgres.database.azure.com dbname=mmgtest user=hstandeffer@capstonealaindexing2018 password=Alaindexing!\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "#declare array for dataframes\n",
    "dfs = []\n",
    "\n",
    "# iterate thru PlayByPlay\n",
    "for playbyplay in os.listdir(folder):\n",
    "\n",
    "    name = os.fsdecode(playbyplay)\n",
    "    path = os.path.join(folder, name)\n",
    "\n",
    "    #iterate thru Play by Play \n",
    "    for year in os.listdir(path):\n",
    "\n",
    "        yearName = os.fsdecode(year)\n",
    "        yearPath = os.path.join(path, yearName) \n",
    "        \n",
    "        print(yearName)\n",
    "        \n",
    "        #iterate thru Year\n",
    "        for pbp in os.listdir(yearPath):\n",
    "\n",
    "            pbpName = os.fsdecode(pbp)\n",
    "            pbpPath = os.path.join(yearPath, pbpName)\n",
    "            \n",
    "            #iterate thru Play By Play\n",
    "            for file in os.listdir(pbpPath):\n",
    "                    \n",
    "                fileName = os.fsdecode(file)\n",
    "                filePath = os.path.join(pbpPath, fileName)\n",
    "                    \n",
    "                string = 'JSON'\n",
    "                    \n",
    "                if fileName == string:\n",
    "                                     \n",
    "                    #iterate thru JSON\n",
    "                    for week in os.listdir(filePath):\n",
    "\n",
    "                        #get name and path\n",
    "                        weekName = os.fsdecode(week)\n",
    "                        weekPath = os.path.join(filePath, weekName)\n",
    "\n",
    "                        #iterate thru Week\n",
    "                        for flat in os.listdir(weekPath):\n",
    "\n",
    "                            flatName = os.fsdecode(flat)\n",
    "                            flatPath = os.path.join(weekPath, flatName)\n",
    "\n",
    "                            #finding flattened folder\n",
    "                            string = 'flattened'\n",
    "\n",
    "                            if flatName == string:\n",
    "\n",
    "                                #iterate thru flattened \n",
    "                                for game in os.listdir(flatPath):\n",
    "\n",
    "                                    gameName = os.fsdecode(game)\n",
    "                                    gamePath = os.path.join(flatPath, gameName)\n",
    "\n",
    "                                    # find all json files\n",
    "                                    if gameName.endswith(\".json\"): \n",
    "\n",
    "                                        # read json file to dataframe\n",
    "                                        df = pd.read_json(os.path.join(gamePath), orient='columns')\n",
    "                                    \n",
    "                                        # add dataframe to list of dataframes\n",
    "                                        dfs.append(df)\n",
    "                                        \n",
    "                                        continue\n",
    "                                    else:\n",
    "                                        continue                                \n",
    "                                continue\n",
    "                            else:\n",
    "                                continue\n",
    "                    continue\n",
    "                else:\n",
    "                    continue\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine list into one dataframe\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "# remove commas from descriptions to avoid erros\n",
    "df['description'] = df['description'].str.replace('[^\\w\\s]', '')\n",
    "\n",
    "# normalize dataframes \n",
    "dfGame = df[['awayAbbr', 'awayId', 'awayTeam', 'gameId', 'homeAbbr', 'homeId', 'homeTeam']]\n",
    "dfDrive = df[['defenseAbbr', 'defenseId', 'defenseTeam', 'driveIndex', 'gameId', 'offenseAbbr', 'offenseId',\n",
    "             'offenseTeam', 'quarter', 'week', 'year']]\n",
    "dfPlay = df[['awayScore', 'clock', 'defenseId', 'description', 'distance', 'down', \n",
    "             'driveIndex', 'endYardLine', 'homeScore', 'offenseId', \n",
    "              'playIndex', 'type', 'yardLine', 'yardsGained', 'week', 'year']]\n",
    "\n",
    "# remove duplicates from game and drive \n",
    "dfGame.drop_duplicates(subset =\"gameId\", keep = 'first', inplace = True) \n",
    "dfDrive.drop_duplicates(subset = [\"defenseId\", \"driveIndex\", \"offenseId\", \"week\", \"year\"], keep = 'first', inplace = True)\n",
    "\n",
    "# array for file names and table names \n",
    "fileNames = ['game', 'drive', 'play']\n",
    "\n",
    "# array for normalized dataframes\n",
    "dfNormalized = [dfGame, dfDrive, dfPlay]\n",
    "\n",
    "# loop to add files to postgres database\n",
    "for df, file in zip(dfNormalized, fileNames):\n",
    "\n",
    "    print(df.shape)\n",
    "    print(file)\n",
    "    \n",
    "    # writes dataframe to a csv \n",
    "    df.to_csv(r'C:\\Users\\mmgri\\Desktop\\csv\\\\' + file + '.csv', sep=',', index=False)\n",
    "    fileString = r'C:\\Users\\mmgri\\Desktop\\csv\\\\' + file + '.csv'\n",
    "    \n",
    "    # loads csv to database \n",
    "    with open(fileString, 'r') as f:\n",
    "        next(f)\n",
    "        cur = conn.cursor()\n",
    "        cur.copy_from(f, file, sep=',')\n",
    "        conn.commit()\n",
    "        \n",
    "    print(file + ' completed.')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
