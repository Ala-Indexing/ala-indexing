{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas is a python data analysis library used for dataframes in this script \n",
    "# https://pandas.pydata.org/\n",
    "\n",
    "# psycopg2 is a postgres database adapter for python used for database connection & migration in this script\n",
    "# http://initd.org/psycopg/docs/\n",
    "\n",
    "# os is a directory of miscellaneous operating system interfaces for python\n",
    "# used to decode file names and list all files in a directory in this script\n",
    "# https://docs.python.org/3/library/os.html\n",
    "\n",
    "# import json to work with json files\n",
    "\n",
    "import pandas as pd\n",
    "import psycopg2 as p\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This script handles a folder containing a years worth of json play-by-play data.\n",
    "# This script handles the FLATTENED json files.\n",
    "\n",
    "# The script:  \n",
    "# 1) iterates through each week file in the year file\n",
    "# 2) finds the flattened file\n",
    "# 3) reads the data into a dataframe \n",
    "# 4) normalizes the data into game and play \n",
    "# 5) writes each dataframe to a csv\n",
    "# 6) uploads the csvs to a database's relating tables \n",
    "\n",
    "\n",
    "# path to folder with year of files\n",
    "year = r'C:\\Users\\mmgri\\Desktop\\2005'\n",
    "\n",
    "# creating database connection string\n",
    "conn = p.connect(\"host=capstonealaindexing2018.postgres.database.azure.com dbname=mmgtest user=hstandeffer@capstonealaindexing2018 password=Alaindexing!\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "#declare array for dataframes\n",
    "dfs = []\n",
    "\n",
    "#iterate thru each week\n",
    "for week in os.listdir(year):\n",
    "    \n",
    "        #get name and path\n",
    "        weekName = os.fsdecode(week)\n",
    "        weekPath = os.path.join(year, weekName)\n",
    "        \n",
    "        #iterate thru files in week\n",
    "        for flat in os.listdir(weekPath):\n",
    "            \n",
    "            flatName = os.fsdecode(flat)\n",
    "            flatPath = os.path.join(weekPath, flatName)\n",
    "\n",
    "            #finding flattened folder\n",
    "            string = 'flattened'\n",
    "            \n",
    "            if flatName == string:\n",
    "\n",
    "                for game in os.listdir(flatPath):\n",
    "\n",
    "                    gameName = os.fsdecode(game)\n",
    "                    gamePath = os.path.join(flatPath, gameName)\n",
    "                        \n",
    "                    print(gameName)\n",
    "\n",
    "                    # find all json files\n",
    "                    if gameName.endswith(\".json\"): \n",
    "\n",
    "                        # read json file to dataframe\n",
    "                        df = pd.read_json(os.path.join(gamePath), orient='columns')\n",
    "\n",
    "                        # add dataframe to list of dataframes\n",
    "                        dfs.append(df)\n",
    "                        continue\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "# combine list into one dataframe\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "# remove commas from descriptions to avoid erros\n",
    "df['description'] = df['description'].str.replace('[^\\w\\s]', '')\n",
    "\n",
    "# normalize dataframes \n",
    "dfGame = df[['awayAbbr', 'awayId', 'awayTeam', 'gameId', 'homeAbbr', 'homeId', 'homeTeam', 'week', 'year']]\n",
    "dfDrive = df[['defenseAbbr', 'defenseId', 'defenseTeam', 'driveIndex', 'gameId', 'offenseAbbr', 'offenseId',\n",
    "             'offenseTeam', 'quarter']]\n",
    "dfPlay = df[['awayScore', 'clock', 'defenseId', 'description', 'distance', 'down', \n",
    "             'driveIndex', 'endYardLine', 'homeScore', 'offenseId', \n",
    "              'playIndex', 'type', 'yardLine', 'yardsGained']]\n",
    "\n",
    "# remove duplicates from game and drive \n",
    "dfGame.drop_duplicates(subset =\"gameId\", keep = 'first', inplace = True) \n",
    "dfDrive.drop_duplicates(subset = [\"defenseId\", \"driveIndex\", \"offenseId\"], keep = 'first', inplace = True)\n",
    "\n",
    "# array for file names and table names \n",
    "fileNames = ['game', 'drive', 'play']\n",
    "\n",
    "# array for normalized dataframes\n",
    "dfNormalized = [dfGame, dfDrive, dfPlay]\n",
    "\n",
    "# loop to add files to postgres database\n",
    "for df, file in zip(dfNormalized, fileNames):\n",
    "    print(df.shape)\n",
    "    print(file)\n",
    "    \n",
    "    # writes dataframe to a csv \n",
    "    df.to_csv(r'C:\\Users\\mmgri\\Desktop\\csv\\\\' + file + '.csv', sep=',', index=False)\n",
    "    fileString = r'C:\\Users\\mmgri\\Desktop\\csv\\\\' + file + '.csv'\n",
    "    \n",
    "    # loads csv to database \n",
    "    with open(fileString, 'r') as f:\n",
    "        next(f)\n",
    "        cur = conn.cursor()\n",
    "        cur.copy_from(f, file, sep=',')\n",
    "        conn.commit()\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
